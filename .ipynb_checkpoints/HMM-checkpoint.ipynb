{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The goal of this notebook is to:\n",
    "1) program the HMM algorithm\n",
    "2) apply HMMs to sensor data for localization/activity recognition\n",
    "\n",
    "For (2), HMMs are applied to gas sensor data that reacts in different measurement sequences to different stimuli.\n",
    "We want to distinguish between the stimuli, given observations from the sensor. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hmmlearn # 0.2.3\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MY_SEED = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/LaCie/Documents/repos/hmms'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import data\n",
    "\"\"\"\n",
    "\n",
    "data_dir = \"/Volumes/LaCie/datasets/HT_Sensor_UCIsubmission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 239 ms, total: 1.98 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 16.3s to load in data using numpy; 2.38s using pandas\n",
    "\n",
    "# From https://github.com/thmosqueiro/ENose-Decorr_Humdt_Temp\n",
    "# Variable metadata has all the metadata, and dataset has the actual recordings\n",
    "\n",
    "\"\"\"\n",
    "For each induction, we include one hour of background activity prior to and after the stimulus presentation. \n",
    "Time series were recorded at one sample per second, with minor variations at some data points due to issues in \n",
    "the wireless communication. For details on which sensors were used and how the time series is organized, \n",
    "see Attribute Information below. \n",
    "\n",
    "The metadata stored in file HT_Sensor_metadata.dat is divided in the following columns: \n",
    "\n",
    "* id: identification of the induction, to be matched with id in file HT_Sensor_dataset.dat; \n",
    "* date: day, month and year when this induction was recorded; \n",
    "* class: what was used to generate this induction (wine, banana or background); \n",
    "* t0: time in hours in which the induction started (represents the time zero in file HT_Sensor_dataset.dat); \n",
    "* dt: interval that this induction lasted. \n",
    "\n",
    "The dataset is composed of 100 snippets of time series, each being a single induction or background activity. \n",
    "On total, there are 919438 points. For each induction, the time when the stimulus was presented is set to zero. \n",
    "For the actual time, see column t0 of the metadata file. \n",
    "In file HT_Sensor_dataset.dat, each column has a title according to the following \n",
    "\n",
    "* id: identification of the induction, to be matched with id in file HT_Sensor_metadata.dat; \n",
    "* time: time in hours, where zero is the start of the induction; \n",
    "* R1 â€“ R8: value of each of the 8 MOX sensors resistance at that time; \n",
    "* Temp.: measurement of temperature in Celsius at that time; \n",
    "* Humidity: measurement of humidity in percent at that time. \n",
    "\n",
    "\n",
    "Temperature and humidity were measured using the Sensirion SHT75.\n",
    "The 8 MOX sensors are commercially available from Figaro, and are detailed below: \n",
    "R1: TGS2611 \n",
    "R2: TGS2612 \n",
    "R3: TGS2610 \n",
    "R4: TGS2600 \n",
    "R5: TGS2602 \n",
    "R6: TGS2602 \n",
    "R7: TGS2620 \n",
    "R8: TGS2620 \n",
    "\"\"\"\n",
    "\n",
    "## Importing dataset\n",
    "# metadata = np.loadtxt(os.path.join(data_dir, \"HT_Sensor_metadata.dat\"), skiprows=1, dtype=str)\n",
    "metadata = pd.read_csv(os.path.join(data_dir, \"HT_Sensor_metadata.dat\"), sep=\"\\s+\")\n",
    "\n",
    "## Loading the dataset\n",
    "# dataset = np.loadtxt(os.path.join(data_dir, \"HT_Sensor_dataset.dat\"), skiprows=1)\n",
    "dataset = pd.read_csv(os.path.join(data_dir, \"HT_Sensor_dataset.dat\"), sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "      <th>t0</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>07-05-15</td>\n",
       "      <td>wine</td>\n",
       "      <td>19.61</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>07-06-15</td>\n",
       "      <td>wine</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>07-09-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>6.49</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>07-09-15</td>\n",
       "      <td>wine</td>\n",
       "      <td>20.07</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      date   class     t0    dt\n",
       "0   0  07-04-15  banana  13.49  1.64\n",
       "1   1  07-05-15    wine  19.61  0.54\n",
       "2   2  07-06-15    wine  19.99  0.66\n",
       "3   3  07-09-15  banana   6.49  0.72\n",
       "4   4  07-09-15    wine  20.07  0.53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata[:5]\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>12.8621</td>\n",
       "      <td>10.3683</td>\n",
       "      <td>10.4383</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>13.3423</td>\n",
       "      <td>8.04169</td>\n",
       "      <td>8.73901</td>\n",
       "      <td>26.2257</td>\n",
       "      <td>59.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>12.8617</td>\n",
       "      <td>10.3682</td>\n",
       "      <td>10.4375</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4927</td>\n",
       "      <td>13.3412</td>\n",
       "      <td>8.04133</td>\n",
       "      <td>8.73908</td>\n",
       "      <td>26.2308</td>\n",
       "      <td>59.0299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999194</td>\n",
       "      <td>12.8607</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6696</td>\n",
       "      <td>13.4924</td>\n",
       "      <td>13.3405</td>\n",
       "      <td>8.04101</td>\n",
       "      <td>8.73915</td>\n",
       "      <td>26.2365</td>\n",
       "      <td>59.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998916</td>\n",
       "      <td>12.8602</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4921</td>\n",
       "      <td>13.3398</td>\n",
       "      <td>8.04086</td>\n",
       "      <td>8.73936</td>\n",
       "      <td>26.2416</td>\n",
       "      <td>58.9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998627</td>\n",
       "      <td>12.8595</td>\n",
       "      <td>10.3688</td>\n",
       "      <td>10.4374</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4919</td>\n",
       "      <td>13.3390</td>\n",
       "      <td>8.04087</td>\n",
       "      <td>8.73986</td>\n",
       "      <td>26.2462</td>\n",
       "      <td>58.9736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time       R1       R2       R3       R4       R5       R6  \\\n",
       "0   0 -0.999750  12.8621  10.3683  10.4383  11.6699  13.4931  13.3423   \n",
       "1   0 -0.999472  12.8617  10.3682  10.4375  11.6697  13.4927  13.3412   \n",
       "2   0 -0.999194  12.8607  10.3686  10.4370  11.6696  13.4924  13.3405   \n",
       "3   0 -0.998916  12.8602  10.3686  10.4370  11.6697  13.4921  13.3398   \n",
       "4   0 -0.998627  12.8595  10.3688  10.4374  11.6699  13.4919  13.3390   \n",
       "\n",
       "        R7       R8    Temp.  Humidity  \n",
       "0  8.04169  8.73901  26.2257   59.0528  \n",
       "1  8.04133  8.73908  26.2308   59.0299  \n",
       "2  8.04101  8.73915  26.2365   59.0093  \n",
       "3  8.04086  8.73936  26.2416   58.9905  \n",
       "4  8.04087  8.73986  26.2462   58.9736  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[:10, :]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_merged = pd.merge(dataset, metadata, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "time        0\n",
       "R1          0\n",
       "R2          0\n",
       "R3          0\n",
       "R4          0\n",
       "R5          0\n",
       "R6          0\n",
       "R7          0\n",
       "R8          0\n",
       "Temp.       0\n",
       "Humidity    0\n",
       "date        0\n",
       "class       0\n",
       "t0          0\n",
       "dt          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_merged.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "      <th>t0</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>12.8621</td>\n",
       "      <td>10.3683</td>\n",
       "      <td>10.4383</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>13.3423</td>\n",
       "      <td>8.04169</td>\n",
       "      <td>8.73901</td>\n",
       "      <td>26.2257</td>\n",
       "      <td>59.0528</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>12.8617</td>\n",
       "      <td>10.3682</td>\n",
       "      <td>10.4375</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4927</td>\n",
       "      <td>13.3412</td>\n",
       "      <td>8.04133</td>\n",
       "      <td>8.73908</td>\n",
       "      <td>26.2308</td>\n",
       "      <td>59.0299</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999194</td>\n",
       "      <td>12.8607</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6696</td>\n",
       "      <td>13.4924</td>\n",
       "      <td>13.3405</td>\n",
       "      <td>8.04101</td>\n",
       "      <td>8.73915</td>\n",
       "      <td>26.2365</td>\n",
       "      <td>59.0093</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998916</td>\n",
       "      <td>12.8602</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4921</td>\n",
       "      <td>13.3398</td>\n",
       "      <td>8.04086</td>\n",
       "      <td>8.73936</td>\n",
       "      <td>26.2416</td>\n",
       "      <td>58.9905</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998627</td>\n",
       "      <td>12.8595</td>\n",
       "      <td>10.3688</td>\n",
       "      <td>10.4374</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4919</td>\n",
       "      <td>13.3390</td>\n",
       "      <td>8.04087</td>\n",
       "      <td>8.73986</td>\n",
       "      <td>26.2462</td>\n",
       "      <td>58.9736</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time       R1       R2       R3       R4       R5       R6  \\\n",
       "0   0 -0.999750  12.8621  10.3683  10.4383  11.6699  13.4931  13.3423   \n",
       "1   0 -0.999472  12.8617  10.3682  10.4375  11.6697  13.4927  13.3412   \n",
       "2   0 -0.999194  12.8607  10.3686  10.4370  11.6696  13.4924  13.3405   \n",
       "3   0 -0.998916  12.8602  10.3686  10.4370  11.6697  13.4921  13.3398   \n",
       "4   0 -0.998627  12.8595  10.3688  10.4374  11.6699  13.4919  13.3390   \n",
       "\n",
       "        R7       R8    Temp.  Humidity      date   class     t0    dt  \n",
       "0  8.04169  8.73901  26.2257   59.0528  07-04-15  banana  13.49  1.64  \n",
       "1  8.04133  8.73908  26.2308   59.0299  07-04-15  banana  13.49  1.64  \n",
       "2  8.04101  8.73915  26.2365   59.0093  07-04-15  banana  13.49  1.64  \n",
       "3  8.04086  8.73936  26.2416   58.9905  07-04-15  banana  13.49  1.64  \n",
       "4  8.04087  8.73986  26.2462   58.9736  07-04-15  banana  13.49  1.64  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify when the stimulus presented (at time equal to zero)\n",
    "# 100 inductions\n",
    "begin_stimulus = \\\n",
    "dataset_merged.loc[\n",
    "np.logical_and(\n",
    "    np.logical_and(dataset_merged.time.shift() < 0, \n",
    "               dataset_merged.time >= 0),\n",
    "               dataset_merged.id.shift() == dataset.id\n",
    "              ),[\"id\", \"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16385</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25300</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34798</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40601</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      time\n",
       "3429    0  0.000021\n",
       "16385   1  0.000122\n",
       "25300   2  0.000135\n",
       "34798   3  0.000199\n",
       "40601   4  0.000127"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(begin_stimulus.shape[0])\n",
    "begin_stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([95], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID 95 is just missing from the data\n",
    "pd.Series(range(100))[~pd.Series(range(100)).isin(begin_stimulus.id)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(begin_stimulus.id).most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928991, 16)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_merged = \\\n",
    "pd.merge(dataset_merged, begin_stimulus.rename(columns={\"time\": \"begin_time\"}), on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928991, 17)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "      <th>t0</th>\n",
       "      <th>dt</th>\n",
       "      <th>begin_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>12.8621</td>\n",
       "      <td>10.3683</td>\n",
       "      <td>10.4383</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>13.3423</td>\n",
       "      <td>8.04169</td>\n",
       "      <td>8.73901</td>\n",
       "      <td>26.2257</td>\n",
       "      <td>59.0528</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>12.8617</td>\n",
       "      <td>10.3682</td>\n",
       "      <td>10.4375</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4927</td>\n",
       "      <td>13.3412</td>\n",
       "      <td>8.04133</td>\n",
       "      <td>8.73908</td>\n",
       "      <td>26.2308</td>\n",
       "      <td>59.0299</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999194</td>\n",
       "      <td>12.8607</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6696</td>\n",
       "      <td>13.4924</td>\n",
       "      <td>13.3405</td>\n",
       "      <td>8.04101</td>\n",
       "      <td>8.73915</td>\n",
       "      <td>26.2365</td>\n",
       "      <td>59.0093</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998916</td>\n",
       "      <td>12.8602</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4921</td>\n",
       "      <td>13.3398</td>\n",
       "      <td>8.04086</td>\n",
       "      <td>8.73936</td>\n",
       "      <td>26.2416</td>\n",
       "      <td>58.9905</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998627</td>\n",
       "      <td>12.8595</td>\n",
       "      <td>10.3688</td>\n",
       "      <td>10.4374</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4919</td>\n",
       "      <td>13.3390</td>\n",
       "      <td>8.04087</td>\n",
       "      <td>8.73986</td>\n",
       "      <td>26.2462</td>\n",
       "      <td>58.9736</td>\n",
       "      <td>07-04-15</td>\n",
       "      <td>banana</td>\n",
       "      <td>13.49</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time       R1       R2       R3       R4       R5       R6  \\\n",
       "0   0 -0.999750  12.8621  10.3683  10.4383  11.6699  13.4931  13.3423   \n",
       "1   0 -0.999472  12.8617  10.3682  10.4375  11.6697  13.4927  13.3412   \n",
       "2   0 -0.999194  12.8607  10.3686  10.4370  11.6696  13.4924  13.3405   \n",
       "3   0 -0.998916  12.8602  10.3686  10.4370  11.6697  13.4921  13.3398   \n",
       "4   0 -0.998627  12.8595  10.3688  10.4374  11.6699  13.4919  13.3390   \n",
       "\n",
       "        R7       R8    Temp.  Humidity      date   class     t0    dt  \\\n",
       "0  8.04169  8.73901  26.2257   59.0528  07-04-15  banana  13.49  1.64   \n",
       "1  8.04133  8.73908  26.2308   59.0299  07-04-15  banana  13.49  1.64   \n",
       "2  8.04101  8.73915  26.2365   59.0093  07-04-15  banana  13.49  1.64   \n",
       "3  8.04086  8.73936  26.2416   58.9905  07-04-15  banana  13.49  1.64   \n",
       "4  8.04087  8.73986  26.2462   58.9736  07-04-15  banana  13.49  1.64   \n",
       "\n",
       "   begin_time  \n",
       "0    0.000021  \n",
       "1    0.000021  \n",
       "2    0.000021  \n",
       "3    0.000021  \n",
       "4    0.000021  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data dictionary states that there is approximately one hour of observations both pre and post \n",
    "# stimulus presentation.\n",
    "# How many observations are there before and after the stimulus, for each induction?\n",
    "\n",
    "dataset_merged.loc[:, \"post_stimulus\"] = dataset_merged.time >= dataset_merged.begin_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_post_cts = \\\n",
    "dataset_merged.groupby([\"id\", \"post_stimulus\"])[\"time\"].count()\n",
    "\n",
    "pre_post_pcts = pre_post_cts / pre_post_cts.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id   post_stimulus\n",
       "0.0  False            0.267577\n",
       "     True             0.732423\n",
       "1.0  False            0.400494\n",
       "     True             0.599506\n",
       "2.0  False            0.375974\n",
       "     True             0.624026\n",
       "3.0  False            0.383607\n",
       "     True             0.616393\n",
       "4.0  False            0.012046\n",
       "     True             0.987954\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_post_pcts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x105f8d8d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAENCAYAAAD0eSVZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDR4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO do: consider getting rid of outliers with abnormal post_stimulus % (should be around 50%)\n",
    "pre_post_pcts.unstack().plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use cases: \n",
    "\n",
    "1) NLP data\n",
    "2) Sensor data, https://archive.ics.uci.edu/ml/datasets/Gas+sensors+for+home+activity+monitoring#\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!!! USE CASE 2 SHOWN BELOW !!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As a first POC for the HMM-based activity recognition, use only the post-stimulus measurements.\n",
    "\n",
    "# todo: Discard measurements that obviously too short (likelihood of less than <<)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586570, 13)\n"
     ]
    }
   ],
   "source": [
    "data_hmm = dataset_merged.loc[dataset_merged.time >= 0, \n",
    "                              [c for c in dataset_merged.columns if c not in \n",
    "                               [\"date\", \"t0\", \"dt\", \"begin_time\", \"post_stimulus\"]]\n",
    "                             ]\n",
    "\n",
    "print(data_hmm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>12.8102</td>\n",
       "      <td>10.3665</td>\n",
       "      <td>10.4529</td>\n",
       "      <td>11.6742</td>\n",
       "      <td>13.4941</td>\n",
       "      <td>13.2749</td>\n",
       "      <td>8.30531</td>\n",
       "      <td>9.04553</td>\n",
       "      <td>26.4234</td>\n",
       "      <td>59.4725</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>12.8097</td>\n",
       "      <td>10.3655</td>\n",
       "      <td>10.4523</td>\n",
       "      <td>11.6734</td>\n",
       "      <td>13.4934</td>\n",
       "      <td>13.2740</td>\n",
       "      <td>8.30527</td>\n",
       "      <td>9.04545</td>\n",
       "      <td>26.4241</td>\n",
       "      <td>59.4745</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>12.8088</td>\n",
       "      <td>10.3645</td>\n",
       "      <td>10.4516</td>\n",
       "      <td>11.6731</td>\n",
       "      <td>13.4930</td>\n",
       "      <td>13.2730</td>\n",
       "      <td>8.30523</td>\n",
       "      <td>9.04538</td>\n",
       "      <td>26.4246</td>\n",
       "      <td>59.4763</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>12.8080</td>\n",
       "      <td>10.3638</td>\n",
       "      <td>10.4508</td>\n",
       "      <td>11.6727</td>\n",
       "      <td>13.4922</td>\n",
       "      <td>13.2719</td>\n",
       "      <td>8.30520</td>\n",
       "      <td>9.04516</td>\n",
       "      <td>26.4251</td>\n",
       "      <td>59.4779</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>12.8078</td>\n",
       "      <td>10.3628</td>\n",
       "      <td>10.4503</td>\n",
       "      <td>11.6722</td>\n",
       "      <td>13.4914</td>\n",
       "      <td>13.2708</td>\n",
       "      <td>8.30517</td>\n",
       "      <td>9.04511</td>\n",
       "      <td>26.4256</td>\n",
       "      <td>59.4793</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      time       R1       R2       R3       R4       R5       R6  \\\n",
       "3429  0.0  0.000021  12.8102  10.3665  10.4529  11.6742  13.4941  13.2749   \n",
       "3430  0.0  0.000309  12.8097  10.3655  10.4523  11.6734  13.4934  13.2740   \n",
       "3431  0.0  0.000587  12.8088  10.3645  10.4516  11.6731  13.4930  13.2730   \n",
       "3432  0.0  0.000865  12.8080  10.3638  10.4508  11.6727  13.4922  13.2719   \n",
       "3433  0.0  0.001144  12.8078  10.3628  10.4503  11.6722  13.4914  13.2708   \n",
       "\n",
       "           R7       R8    Temp.  Humidity   class  \n",
       "3429  8.30531  9.04553  26.4234   59.4725  banana  \n",
       "3430  8.30527  9.04545  26.4241   59.4745  banana  \n",
       "3431  8.30523  9.04538  26.4246   59.4763  banana  \n",
       "3432  8.30520  9.04516  26.4251   59.4779  banana  \n",
       "3433  8.30517  9.04511  26.4256   59.4793  banana  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hmm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Divide the dataset into train and holdout sets, \n",
    "where train is used to estimate the HMM parameters,\n",
    "and holdout will be used to quantify the accuracy of the subsequent estimation. \n",
    "\n",
    "Stratified sample over stimulus types. \n",
    "\n",
    "See how validation improves with increased training data. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "background    30\n",
       "banana        33\n",
       "wine          36\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hmm.groupby(\"class\")[\"id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo: experiment with perturbing these\n",
    "min_sample_length = 0\n",
    "max_sample_length = np.float(\"inf\")\n",
    "\n",
    "max_samples_per_class = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids = metadata.groupby(\"class\")[\"id\"].apply(lambda x: x.sample(n = max_samples_per_class, \n",
    "                                                                     random_state = MY_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout_data = metadata.loc[~metadata.id.isin(train_ids.values), [\"class\", \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout_ids = holdout_data.groupby(\"class\")[\"id\"].apply(lambda x: x.sample(n = 10, random_state = MY_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids.rename_axis(index=[\"class\", \"id\"], inplace=True)\n",
    "holdout_ids.rename_axis(index=[\"class\", \"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids[train_ids > -1] = \"train\"\n",
    "holdout_ids[holdout_ids > -1] = \"holdout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_holdout_label = pd.concat([train_ids, holdout_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_holdout_label.name = \"train_holdout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_hmm = pd.merge(data_hmm, train_holdout_label, how=\"left\", on=[\"class\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WHOOPS my observation variables are continuous - should I use a particle filter? Or I could bin them. \n",
    "\n",
    "Trying the HMM with binning first.\n",
    "TODO Secondly, will try a particle filter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Investigate how to cut the bins for each of the continuous observation variables. \n",
    "# Use k equal width bins, after discarding the most extreme 2% from each tail of the distribution \n",
    "# (mitigate influence of outliers). \n",
    "\n",
    "bin_ct_discretize = 5 # 10\n",
    "cap_extreme_pct = .02  # between 0 and 1\n",
    "\n",
    "vars_to_discretize = [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\", \"R6\", \"R7\", \"R8\", \"Temp.\", \"Humidity\"]\n",
    "vars_binned = [\"_\".join((v, \"binned\")) for v in vars_to_discretize] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/LaCie/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Volumes/LaCie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Volumes/LaCie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.09 s, sys: 979 ms, total: 4.06 s\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5.63s\n",
    "for var in vars_to_discretize:\n",
    "    var_data = data_hmm[[var]]\n",
    "    # Create the histogram\n",
    "    cap_low = np.percentile(var_data, cap_extreme_pct * 100)\n",
    "    cap_high = np.percentile(var_data, (1 - cap_extreme_pct) * 100)\n",
    "    var_data.loc[(var_data < cap_low).values.flatten()] = cap_low\n",
    "    var_data.loc[(var_data > cap_high).values.flatten()] = cap_high\n",
    "    data_hmm[var + \"_binned\"] = pd.cut(var_data.values.flatten(), bin_ct_discretize, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a204c32b0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a20780c88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x105ee41d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1a1e2692b0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a2078e908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a2077cf98>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1a207a1668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a2060ecf8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a206023c8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1a2080ca58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a207f2128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a208187b8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAJOCAYAAAAK8VsYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTZIkqeMs2CRJkjrOgk2SJKnj/j91mWtvZnBzZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_hmm[vars_binned].hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>time</th>\n",
       "      <th>train_holdout</th>\n",
       "      <th>R1_binned</th>\n",
       "      <th>R2_binned</th>\n",
       "      <th>R3_binned</th>\n",
       "      <th>R4_binned</th>\n",
       "      <th>R5_binned</th>\n",
       "      <th>R6_binned</th>\n",
       "      <th>R7_binned</th>\n",
       "      <th>R8_binned</th>\n",
       "      <th>Temp._binned</th>\n",
       "      <th>Humidity_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   class      time train_holdout  R1_binned  R2_binned  R3_binned  \\\n",
       "0   0  banana  0.000021         train          4          4          4   \n",
       "1   0  banana  0.000309         train          4          4          4   \n",
       "2   0  banana  0.000587         train          4          4          4   \n",
       "3   0  banana  0.000865         train          4          4          4   \n",
       "4   0  banana  0.001144         train          4          4          4   \n",
       "\n",
       "   R4_binned  R5_binned  R6_binned  R7_binned  R8_binned  Temp._binned  \\\n",
       "0          4          0          1          4          4             1   \n",
       "1          4          0          1          4          4             1   \n",
       "2          4          0          1          4          4             1   \n",
       "3          4          0          1          4          4             1   \n",
       "4          4          0          1          4          4             1   \n",
       "\n",
       "   Humidity_binned  \n",
       "0                2  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  "
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hmm_discrete = data_hmm[[\"id\", \"class\", \"time\", \"train_holdout\"] + vars_binned]\n",
    "data_hmm_discrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_hmm_train = \\\n",
    "data_hmm_discrete.loc[data_hmm_discrete.train_holdout == \"train\", [c for c in data_hmm_discrete.columns if c != \"train_holdout\"]]\n",
    "\n",
    "data_hmm_holdout = \\\n",
    "data_hmm_discrete.loc[data_hmm_discrete.train_holdout == \"holdout\", [c for c in data_hmm_discrete.columns if c != \"train_holdout\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "THIS SECTION BUILDS OUT THE HMM CLASS FROM SCRATCH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learn the parameters of an HMM (transition probabilities; emission probabilities).\n",
    "Make assumption about prior probabilities of start state? Seems uniform is assumed by default. \n",
    "\n",
    "Maximum likelihood; using Baum-Welch (local maximum) or MCMC. \n",
    "Also approximate variational inference (slightly less accurate than MCMC, but better computational complexity). \n",
    "\n",
    "Note, the sensor process suits the stationary markov assumptions well. \n",
    "The discrete state space suits an HMM. \n",
    "Note though that the state will be static, so we need only model the emission probabilities. \n",
    "I guess we don't know the state is static though- can we detect this?\n",
    "\n",
    "Follow-up:\n",
    "If I splice different sequences together, can the HMM still differentiate amongst signals?\n",
    "How about depending on how noisy is the splicing/frequency of transitions?\n",
    "\n",
    "If I did this I suspect the HMM would fail, as transitions are essentially random.\n",
    "Now, if I included both pre/post stimulus and included 'time' as a state variable it should be possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multilevel HMM estimation\n",
    "\"\"\"\n",
    "Should make 2 classes, one for discrete obs vectors and one for continuous, \n",
    "then use inheritance from a master HMM class?\n",
    "\n",
    "But may have a mix of discrete and continuous vectors... I'll ignore that case for now, \n",
    "implementation seems complicated. \n",
    "\n",
    "OO Implement multiple B matrices for the discrete case as well. \n",
    "Multiply probability of seeing obs given hidden state, across all obs sequences of different types/sensors\n",
    "(assuming sequences are independent).\n",
    "\n",
    "...What about modeling concatenation of multiple disparate continuous signals??\n",
    "Multivariate mixtures of gaussians?\n",
    "Fit a GMM for each separate observation dimension (ie multiple B matrices)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class hmm_multi_discrete():\n",
    "    \"\"\"\n",
    "    Assume HMM observations Y and hidden states X (both discrete and finite).\n",
    "    A = transition probabilities; a_ij = prob X_t = j given X_t-1 = i\n",
    "    B = emission probabilities; b_j(y_i) = prob Y_t = y_i given X_t = j\n",
    "    pi = initial state distribution; pi_i = prob X_1 = i\n",
    "    \n",
    "    alpha_i(t) = Probability of observation sequence y_1 to y_t and state X_t = i at time t given current HMM parameters\n",
    "    beta_i(t) = Probability of observation sequence y_t+1 to y_T given X_t = i and current HMM parameters\n",
    "    \n",
    "    Baum-Welch finds a local maximum.\n",
    "    Implemented according to https://en.wikipedia.org/wiki/Baum–Welch_algorithm\n",
    "    Followed Rabiner's HMM Tutorial on scaling the calculations (forward, backward)\n",
    "    or using the log domain (Viterbi) to avoid numerical underflow. \n",
    "    \n",
    "    As-is, the code is extended to multiple sequences of the same type. \n",
    "    To do: To extend to multiple observation sequences of different types (sensor fusion), \n",
    "    need to learn multiple B matrices!\n",
    "    I want the sequences to share the A matrix, though this might not result in significant increased accuracy.\n",
    "    It shouldn't hurt though, and it should be more computationally efficient. \n",
    "    \n",
    "    Alternatively, for multiple sequences of different types, can I just run k different HMMs and average results?\n",
    "    \n",
    "    An obvious 3rd option would be to take the cross-product of the emission spaces of the multiple\n",
    "    different types of sensors and treat that as a single sensor. However, this may suffer from \n",
    "    data sparsity issues. \n",
    "    If sparsity isn't an issue however, it would be more accurate than the above methods as it removes\n",
    "    the assumption about independence among sensor types. \n",
    "    The existing code is already sufficient to handle this approach. Going with this as a first approach. \n",
    "    Desire further testing amongst the 3 methods. \n",
    "    \"\"\"\n",
    "    def __init__(self, A, B, pi):\n",
    "        \"\"\"\n",
    "        A, B, pi numpy arrays\n",
    "        A (size of X, size of X); A_ij = transition from x_i to x_j\n",
    "        B (num sensors, size of X, size of Y); B_ij = prob observe y_j given x_i\n",
    "        pi (size of X, 1)\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "        self.num_states = A.shape[0]\n",
    "        self.num_sensors = B.shape[0]  # Assuming this isn't large enough to cause underflow\n",
    "        self.num_emissions = B.shape[2]  # Assuming this is the same for all sensors (ie, quantized)\n",
    "        \n",
    "    def forward(self, y_vector):\n",
    "        \"\"\"\n",
    "        Calculates alpha_i(t) for all states i, and all t. Filtering. \n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        Returns numpy array (T, num states); each row represents alpha_i(t) for 1< t<T\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"fwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in forward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            alpha_prev = np.multiply(self.pi, np.prod([self.B[s, :, y_vector[s, 0]] for s in range(self.num_sensors)], \n",
    "                                                      axis=0).reshape(self.num_states, 1))\n",
    "            result = alpha_prev.copy().T  # one entry for each time t\n",
    "            for h in range(1, t):\n",
    "#                 print(alpha_prev, h)\n",
    "                alpha_prev = np.multiply(np.dot(self.A.T, alpha_prev), \n",
    "                                         np.prod([self.B[s, :, y_vector[s, h]] for s in range(self.num_sensors)], \n",
    "                                                 axis=0).reshape(self.num_states, 1))\n",
    "                alpha_prev = np.divide(alpha_prev, np.sum(alpha_prev))  # scaled version\n",
    "                result = np.vstack((result, alpha_prev.T))\n",
    "            return result\n",
    "    \n",
    "    def backward(self, y_vector, t_past):\n",
    "        \"\"\"\n",
    "        Calculates beta_i(t) for all states i.\n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        t_past integer representing past time ending the backward algorithm\n",
    "        Returns numpy array (T, num states); each row represents beta_i(t) for 1< t<T.\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"bwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in backward algorithm\")\n",
    "            return None\n",
    "        if t_past < 0 or t_past > t:\n",
    "            print(\"Error: invalid t_past in backward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            beta_next = np.ones((self.num_states, 1))\n",
    "            result = beta_next.copy().T\n",
    "            for h in range(t - 2, t_past - 1, -1):\n",
    "#                 print(beta_next, h)\n",
    "                beta_next = np.dot(self.A, \n",
    "                                   np.multiply(np.prod([self.B[s, :, y_vector[s, h + 1]] \n",
    "                                                        for s in range(self.num_sensors)], \n",
    "                                                       axis=0).reshape(self.num_states, 1), \n",
    "                                               beta_next)\n",
    "                                  )\n",
    "                beta_next = np.divide(beta_next, np.sum(beta_next))\n",
    "                result = np.vstack((result, beta_next.T))\n",
    "            result = np.array(result[::-1])\n",
    "            return result\n",
    "    \n",
    "    def forward_backward(self, y_vector):\n",
    "        \"\"\"\n",
    "        Smoothing; Distribution over states of some middle latent variable, \n",
    "        at some point k steps in the past from time t.\n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        Returns numpy array, (T x num_states)\n",
    "        \n",
    "        Note, this implementation has standard time complexity, but slightly higher \n",
    "        space complexity than the standard implementation which does not need to hold beta\n",
    "        in memory. \n",
    "        \"\"\"\n",
    "        alpha = self.forward(y_vector)  # (T, num states)\n",
    "        beta = self.backward(y_vector, 0)  # (T, num states); Compute beta for all possible t (1 to T)\n",
    "        smoothed_estimates = np.multiply(alpha, beta)\n",
    "        return smoothed_estimates\n",
    "    \n",
    "    def update_hmm(self, y_vector_arr):\n",
    "        \"\"\"\n",
    "        Update the parameters of the HMM via one step of E-M Baum-Welch algorithm.\n",
    "        y_vector_arr numpy_array corresponding to the sequences of observations.\n",
    "        y_vector_arr (num_sensors, num_sequences, max time step observed so far)\n",
    "        \"\"\"\n",
    "        # Assume have same number of sequences for each sensor\n",
    "        # Separately for each observation sequence across all sensors, calculate intermediate variables gamma and xi.\n",
    "        num_sequences = y_vector_arr.shape[1]\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        \n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector\")\n",
    "            return None\n",
    "        \n",
    "        results_gamma = []\n",
    "        results_xi = []\n",
    "        for r in range(num_sequences):\n",
    "            y_vector = y_vector_arr[:, r, :]\n",
    "            alpha = self.forward(y_vector)\n",
    "            beta = self.backward(y_vector, 0)  # Compute beta for all possible t (1 to T)\n",
    "        \n",
    "            # Calculate for all i, j, and t:\n",
    "            gamma_i = np.multiply(alpha, beta) # (T x num_states) \n",
    "            gamma_i = np.divide(gamma_i.T, np.sum(gamma_i, axis=1)).T # / (T); result is (T x num_states) \n",
    "            results_gamma.append(gamma_i)\n",
    "            \n",
    "            xi_agg_t = []\n",
    "            for t in range(num_obs_t - 1):\n",
    "                xi_ijt = np.multiply(\n",
    "                    np.multiply(\n",
    "                    np.multiply(self.A, alpha[t, :].reshape(alpha.shape[1], 1)),  # (num_states x num_states)\n",
    "                    beta[t + 1, :]),  # (num_states x num_states)\n",
    "                    np.prod([self.B[s, :, y_vector[s, t + 1]] for s in range(self.num_sensors)], axis=0\n",
    "                           ).reshape(1, self.num_states)  # (num_states x num_states)\n",
    "#                     self.B[:, y_vector[t + 1]].reshape(1, self.B.shape[0])  # (num_states x num_states)\n",
    "                    )   # (start_state, end_state)\n",
    "                xi_ijt = xi_ijt / np.sum(xi_ijt)\n",
    "                xi_agg_t.append(xi_ijt)\n",
    "            xi_agg_t = np.array(xi_agg_t)  # (result is (T-1 x num_states x num_states))\n",
    "            results_xi.append(xi_agg_t)\n",
    "            \n",
    "        results_gamma = np.array(results_gamma)  # result is (num_sequences x T x num_states) \n",
    "        results_xi = np.array(results_xi)  # (result is (num_sequences x T-1 x num_states x num_states))\n",
    "                \n",
    "        # Combining data across sequences, update the parameters of the HMM using the intermediate variables. \n",
    "        pi_new = np.sum(results_gamma[:, 0, :], axis=0).reshape(results_gamma.shape[2], 1) / num_sequences\n",
    "        a_new = np.divide(np.sum(results_xi, axis=(0, 1)),\n",
    "                          np.sum(results_gamma[:, :num_obs_t - 1, :], axis=(0, 1)).reshape(results_gamma.shape[2], 1)\n",
    "                         )\n",
    "        b_new = [[np.sum(\n",
    "                [np.sum(results_gamma[r, [t for t in range(num_obs_t) if y_vector_arr[s, r, t] == k], \n",
    "                                      :].reshape(len([t for t in range(num_obs_t) if y_vector_arr[s, r, t] == k]), \n",
    "                                                         results_gamma.shape[2]), \n",
    "                         axis=0)  # (1 x num_states)\n",
    "                 for r in range(num_sequences)], axis=0)  # (1 x num_states)\n",
    "                 for k in range(self.num_emissions)]  # (num_emissions x num_states)\n",
    "                 for s in range(self.num_sensors)]  # (num_sensors x num_emissions x num_states)\n",
    "        b_new = np.array(b_new)\n",
    "        b_new = np.divide(b_new,  # normalize\n",
    "                          np.sum(results_gamma, axis=(0, 1)))  # (1 x num_states)\n",
    "        b_new = np.moveaxis(b_new, 1, 2)  # (num_sensors x num_states x num_emissions)\n",
    "        \n",
    "        pi_change = np.subtract(self.pi, pi_new)\n",
    "        A_change = np.subtract(self.A, a_new)\n",
    "        B_change = np.subtract(self.B, b_new)\n",
    "        \n",
    "        self.pi = pi_new\n",
    "        self.A = a_new\n",
    "        self.B = b_new\n",
    "        \n",
    "        return [pi_change, A_change, B_change]\n",
    "    \n",
    "    def fit(self, y_vector_arr, max_iter=100, conv_tol=0.01):\n",
    "        \"\"\"\n",
    "        Fits the HMM with specified convergence criteria, using the EM-based update function, Baum-Welch. \n",
    "        \n",
    "        y_vector_arr numpy array (num sensors, num sequences, num observations) of integers in [0, num_emissions]\n",
    "        \"\"\"\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector. Aborting fit.\")\n",
    "            return None\n",
    "        \n",
    "        num_iter = 0\n",
    "        conv_diff = np.float(\"inf\")\n",
    "        while num_iter < max_iter and conv_diff > conv_tol:\n",
    "            pi_change, A_change, B_change = self.update_hmm(y_vector_arr)\n",
    "            conv_diff = max(pi_change.max(), A_change.max(), B_change.max())\n",
    "            num_iter += 1\n",
    "        print(\"%d iterations.\" %(num_iter))\n",
    "        if conv_diff > conv_tol:\n",
    "            print(\"Warning: Baum-Welch not converged at %3.2f.\" %(conv_tol), \"Conv diff of %3.2f\" %(conv_diff))\n",
    "        return None\n",
    "    \n",
    "    def viterbi(self, y_vector_arr):\n",
    "        \"\"\"\n",
    "        Probability of the latent variables:\n",
    "        Most Likely Explanation; Joint probability of the entire sequence of hidden states \n",
    "        that generated an entire sequence of observations. \n",
    "        \n",
    "        y_vector_arr numpy_array corresponding to the sequences of observations.\n",
    "        y_vector_arr (num_sensors, num_sequences, max time step observed so far)\n",
    "        \n",
    "        Todo: How does this extend to multiple observation sequences? \n",
    "        It seems consider all sequences at each step when running forward through time. \n",
    "        Maybe, take the maximal previous state across the product of all sequences, such that\n",
    "        decoded sequence may not be the viterbi solution for any individual sequence. \n",
    "        Or, use the product of the sequences (going with this).\n",
    "        \n",
    "        This assumes sequences are independent, and gives equal importance/weight to each sequence.\n",
    "        Equal weight might not be the best idea if different sequences have different noise levels/\n",
    "        accuracy. \n",
    "        Todo: flexible weights, in this function and throughout class. \n",
    "        Alternatively, first PCA/ICA transform the sequences. (Perhaps a better idea? \n",
    "        Otherwise, the estimation of relative noise levels for each sequence would be manual/\n",
    "        judgmental process)\n",
    "        Still nice to have a manual over-ride. \n",
    "        \"\"\"\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector in viterbi algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Dynamic programming \n",
    "            # Maximal prior sequence given current evidence, conditioned on current state\n",
    "            # Note: to extent to multiple sequences of different types, need to learn different B matrices!\n",
    "            alpha_prev = np.multiply(self.pi, \n",
    "                                     np.prod([self.B[s, :, y_vector_arr[s, :, 0]] \n",
    "                                              for s in range(self.num_sensors)], axis=0))  # (num_states x num_seq)\n",
    "#                                      self.B[:, y_vector_arr[:, 0]])  # (num_states x num_seq)\n",
    "            alpha_prev = np.log(np.prod(alpha_prev, axis=1).reshape(self.num_states, 1))  # aggregate across sequences\n",
    "            result = alpha_prev.copy().T  # one entry for each time t\n",
    "            for h in range(1, num_obs_t):\n",
    "                alpha_prev_new = np.prod([self.B[s, :, y_vector_arr[s, :, h]] \n",
    "                                          for s in range(self.num_sensors)], axis=(0, 1)).reshape(1, self.num_states)\n",
    "#                 alpha_prev_new = np.prod(self.B[:, y_vector_arr[:, h]], axis=1).reshape(1, self.B.shape[0])\n",
    "                alpha_prev = np.add(np.max(np.add(np.log(self.A), alpha_prev), axis=0),  # (1 x num_states)\n",
    "                                    np.log(alpha_prev_new)).T\n",
    "                result = np.vstack((result, alpha_prev.T))\n",
    "        # Backtrack and return the most likely sequence\n",
    "        most_likely_seq = np.argmax(result, axis=1).tolist()\n",
    "        return most_likely_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multilevel HMM estimation\n",
    "\"\"\"\n",
    "!!! NOT UPDATED - IGNORE THIS CODE, IT'S THE SAME AS ABOVE, JUST RENAMED !!!\n",
    "Continuous observation sequence version (GMM)\n",
    "\n",
    "Resources:\n",
    "Rabiner Tutorial\n",
    "Gutierrez-Osuna, http://research.cs.tamu.edu/prism/lectures/sp/l14.pdf\n",
    "\"\"\"\n",
    "\n",
    "class hmm_multi_gmm():\n",
    "    \"\"\"\n",
    "    Assume HMM observations Y and hidden states X (both discrete and finite).\n",
    "    A = transition probabilities; a_ij = prob X_t = j given X_t-1 = i\n",
    "    B = emission probabilities; b_j(y_i) = prob Y_t = y_i given X_t = j\n",
    "    pi = initial state distribution; pi_i = prob X_1 = i\n",
    "    \n",
    "    alpha_i(t) = Probability of observation sequence y_1 to y_t and state X_t = i at time t given current HMM parameters\n",
    "    beta_i(t) = Probability of observation sequence y_t+1 to y_T given X_t = i and current HMM parameters\n",
    "    \n",
    "    Baum-Welch finds a local maximum.\n",
    "    Implemented according to https://en.wikipedia.org/wiki/Baum–Welch_algorithm\n",
    "    Followed Rabiner's HMM Tutorial on scaling the calculations (forward, backward)\n",
    "    or using the log domain (Viterbi) to avoid numerical underflow. \n",
    "    \n",
    "    As-is, the code is extended to multiple sequences of the same type. \n",
    "    To do: To extend to multiple observation sequences of different types (sensor fusion), \n",
    "    need to learn multiple B matrices!\n",
    "    I want the sequences to share the A matrix, though this might not result in significant increased accuracy.\n",
    "    It shouldn't hurt though, and it should be more computationally efficient. \n",
    "    \n",
    "    Alternatively, for multiple sequences of different types, can I just run k different HMMs and average results?\n",
    "    \n",
    "    An obvious 3rd option would be to take the cross-product of the emission spaces of the multiple\n",
    "    different types of sensors and treat that as a single sensor. However, this may suffer from \n",
    "    data sparsity issues. \n",
    "    If sparsity isn't an issue however, it would be more accurate than the above methods as it removes\n",
    "    the assumption about independence among sensor types. \n",
    "    The existing code is already sufficient to handle this approach. Going with this as a first approach. \n",
    "    Desire further testing amongst the 3 methods. \n",
    "    \"\"\"\n",
    "    def __init__(self, A, B, pi):\n",
    "        \"\"\"\n",
    "        A, B, pi numpy arrays\n",
    "        A (size of X, size of X); A_ij = transition from x_i to x_j\n",
    "        B (num sensors, size of X, size of Y); B_ij = prob observe y_j given x_i\n",
    "        pi (size of X, 1)\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "        self.num_states = A.shape[0]\n",
    "        self.num_sensors = B.shape[0]  # Assuming this isn't large enough to cause underflow\n",
    "        self.num_emissions = B.shape[2]  # Assuming this is the same for all sensors (ie, quantized)\n",
    "        \n",
    "    def forward(self, y_vector):\n",
    "        \"\"\"\n",
    "        Calculates alpha_i(t) for all states i, and all t. Filtering. \n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        Returns numpy array (T, num states); each row represents alpha_i(t) for 1< t<T\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"fwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in forward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            alpha_prev = np.multiply(self.pi, np.prod([self.B[s, :, y_vector[s, 0]] for s in range(self.num_sensors)], \n",
    "                                                      axis=0).reshape(self.num_states, 1))\n",
    "            result = alpha_prev.copy().T  # one entry for each time t\n",
    "            for h in range(1, t):\n",
    "#                 print(alpha_prev, h)\n",
    "                alpha_prev = np.multiply(np.dot(self.A.T, alpha_prev), \n",
    "                                         np.prod([self.B[s, :, y_vector[s, h]] for s in range(self.num_sensors)], \n",
    "                                                 axis=0).reshape(self.num_states, 1))\n",
    "                alpha_prev = np.divide(alpha_prev, np.sum(alpha_prev))  # scaled version\n",
    "                result = np.vstack((result, alpha_prev.T))\n",
    "            return result\n",
    "    \n",
    "    def backward(self, y_vector, t_past):\n",
    "        \"\"\"\n",
    "        Calculates beta_i(t) for all states i.\n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        t_past integer representing past time ending the backward algorithm\n",
    "        Returns numpy array (T, num states); each row represents beta_i(t) for 1< t<T.\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"bwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in backward algorithm\")\n",
    "            return None\n",
    "        if t_past < 0 or t_past > t:\n",
    "            print(\"Error: invalid t_past in backward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            beta_next = np.ones((self.num_states, 1))\n",
    "            result = beta_next.copy().T\n",
    "            for h in range(t - 2, t_past - 1, -1):\n",
    "#                 print(beta_next, h)\n",
    "                beta_next = np.dot(self.A, \n",
    "                                   np.multiply(np.prod([self.B[s, :, y_vector[s, h + 1]] \n",
    "                                                        for s in range(self.num_sensors)], \n",
    "                                                       axis=0).reshape(self.num_states, 1), \n",
    "                                               beta_next)\n",
    "                                  )\n",
    "                beta_next = np.divide(beta_next, np.sum(beta_next))\n",
    "                result = np.vstack((result, beta_next.T))\n",
    "            result = np.array(result[::-1])\n",
    "            return result\n",
    "    \n",
    "    def forward_backward(self, y_vector):\n",
    "        \"\"\"\n",
    "        Smoothing; Distribution over states of some middle latent variable, \n",
    "        at some point k steps in the past from time t.\n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        Returns numpy array, (T x num_states)\n",
    "        \n",
    "        Note, this implementation has standard time complexity, but slightly higher \n",
    "        space complexity than the standard implementation which does not need to hold beta\n",
    "        in memory. \n",
    "        \"\"\"\n",
    "        alpha = self.forward(y_vector)  # (T, num states)\n",
    "        beta = self.backward(y_vector, 0)  # (T, num states); Compute beta for all possible t (1 to T)\n",
    "        smoothed_estimates = np.multiply(alpha, beta)\n",
    "        return smoothed_estimates\n",
    "    \n",
    "    def update_hmm(self, y_vector_arr):\n",
    "        \"\"\"\n",
    "        Update the parameters of the HMM via one step of E-M Baum-Welch algorithm.\n",
    "        y_vector_arr numpy_array corresponding to the sequences of observations.\n",
    "        y_vector_arr (num_sensors, num_sequences, max time step observed so far)\n",
    "        \"\"\"\n",
    "        # Assume have same number of sequences for each sensor\n",
    "        # Separately for each observation sequence across all sensors, calculate intermediate variables gamma and xi.\n",
    "        num_sequences = y_vector_arr.shape[1]\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        \n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector\")\n",
    "            return None\n",
    "        \n",
    "        results_gamma = []\n",
    "        results_xi = []\n",
    "        for r in range(num_sequences):\n",
    "            y_vector = y_vector_arr[:, r, :]\n",
    "            alpha = self.forward(y_vector)\n",
    "            beta = self.backward(y_vector, 0)  # Compute beta for all possible t (1 to T)\n",
    "        \n",
    "            # Calculate for all i, j, and t:\n",
    "            gamma_i = np.multiply(alpha, beta) # (T x num_states) \n",
    "            gamma_i = np.divide(gamma_i.T, np.sum(gamma_i, axis=1)).T # / (T); result is (T x num_states) \n",
    "            results_gamma.append(gamma_i)\n",
    "            \n",
    "            xi_agg_t = []\n",
    "            for t in range(num_obs_t - 1):\n",
    "                xi_ijt = np.multiply(\n",
    "                    np.multiply(\n",
    "                    np.multiply(self.A, alpha[t, :].reshape(alpha.shape[1], 1)),  # (num_states x num_states)\n",
    "                    beta[t + 1, :]),  # (num_states x num_states)\n",
    "                    np.prod([self.B[s, :, y_vector[s, t + 1]] for s in range(self.num_sensors)], axis=0\n",
    "                           ).reshape(1, self.num_states)  # (num_states x num_states)\n",
    "#                     self.B[:, y_vector[t + 1]].reshape(1, self.B.shape[0])  # (num_states x num_states)\n",
    "                    )   # (start_state, end_state)\n",
    "                xi_ijt = xi_ijt / np.sum(xi_ijt)\n",
    "                xi_agg_t.append(xi_ijt)\n",
    "            xi_agg_t = np.array(xi_agg_t)  # (result is (T-1 x num_states x num_states))\n",
    "            results_xi.append(xi_agg_t)\n",
    "            \n",
    "        results_gamma = np.array(results_gamma)  # result is (num_sequences x T x num_states) \n",
    "        results_xi = np.array(results_xi)  # (result is (num_sequences x T-1 x num_states x num_states))\n",
    "                \n",
    "        # Combining data across sequences, update the parameters of the HMM using the intermediate variables. \n",
    "        # todo: Do I have to divide out the scale factor, as in Errata to Rabiner? http://alumni.media.mit.edu/~rahimi/rabiner/rabiner-errata/rabiner-errata.html\n",
    "        pi_new = np.sum(results_gamma[:, 0, :], axis=0).reshape(results_gamma.shape[2], 1) / num_sequences\n",
    "        a_new = np.divide(np.sum(results_xi, axis=(0, 1)),\n",
    "                          np.sum(results_gamma[:, :num_obs_t - 1, :], axis=(0, 1)).reshape(results_gamma.shape[2], 1)\n",
    "                         )\n",
    "        b_new = [[np.sum(\n",
    "                [np.sum(results_gamma[r, [t for t in range(num_obs_t) if y_vector_arr[s, r, t] == k], \n",
    "                                      :].reshape(len([t for t in range(num_obs_t) if y_vector_arr[s, r, t] == k]), \n",
    "                                                         results_gamma.shape[2]), \n",
    "                         axis=0)  # (1 x num_states)\n",
    "                 for r in range(num_sequences)], axis=0)  # (1 x num_states)\n",
    "                 for k in range(self.num_emissions)]  # (num_emissions x num_states)\n",
    "                 for s in range(self.num_sensors)]  # (num_sensors x num_emissions x num_states)\n",
    "        b_new = np.array(b_new)\n",
    "        b_new = np.divide(b_new,  # normalize\n",
    "                          np.sum(results_gamma, axis=(0, 1)))  # (1 x num_states)\n",
    "        b_new = np.moveaxis(b_new, 1, 2)  # (num_sensors x num_states x num_emissions)\n",
    "        \n",
    "        pi_change = np.subtract(self.pi, pi_new)\n",
    "        A_change = np.subtract(self.A, a_new)\n",
    "        B_change = np.subtract(self.B, b_new)\n",
    "        \n",
    "        self.pi = pi_new\n",
    "        self.A = a_new\n",
    "        self.B = b_new\n",
    "        \n",
    "        return [pi_change, A_change, B_change]\n",
    "    \n",
    "    def fit(self, y_vector_arr, max_iter=100, conv_tol=0.01):\n",
    "        \"\"\"\n",
    "        Fits the HMM with specified convergence criteria, using the EM-based update function, Baum-Welch. \n",
    "        \n",
    "        y_vector_arr numpy array (num sensors, num sequences, num observations) of integers in [0, num_emissions]\n",
    "        \"\"\"\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector. Aborting fit.\")\n",
    "            return None\n",
    "        \n",
    "        num_iter = 0\n",
    "        conv_diff = np.float(\"inf\")\n",
    "        while num_iter < max_iter and conv_diff > conv_tol:\n",
    "            pi_change, A_change, B_change = self.update_hmm(y_vector_arr)\n",
    "            conv_diff = max(pi_change.max(), A_change.max(), B_change.max())\n",
    "            num_iter += 1\n",
    "        print(\"%d iterations.\" %(num_iter))\n",
    "        if conv_diff > conv_tol:\n",
    "            print(\"Warning: Baum-Welch not converged at %3.2f.\" %(conv_tol), \"Conv diff of %3.2f\" %(conv_diff))\n",
    "        return None\n",
    "    \n",
    "    def viterbi(self, y_vector_arr):\n",
    "        \"\"\"\n",
    "        Probability of the latent variables:\n",
    "        Most Likely Explanation; Joint probability of the entire sequence of hidden states \n",
    "        that generated an entire sequence of observations. \n",
    "        \n",
    "        y_vector_arr numpy_array corresponding to the sequences of observations.\n",
    "        y_vector_arr (num_sensors, num_sequences, max time step observed so far)\n",
    "        \n",
    "        Todo: How does this extend to multiple observation sequences? \n",
    "        It seems consider all sequences at each step when running forward through time. \n",
    "        Maybe, take the maximal previous state across the product of all sequences, such that\n",
    "        decoded sequence may not be the viterbi solution for any individual sequence. \n",
    "        Or, use the product of the sequences (going with this).\n",
    "        TODO: This doesn't make sense if sequences are independent in time. They should be viterbi'd separately.\n",
    "        \n",
    "        This assumes sequences are independent, and gives equal importance/weight to each sequence.\n",
    "        Equal weight might not be the best idea if different sequences have different noise levels/\n",
    "        accuracy. \n",
    "        Todo: flexible weights, in this function and throughout class. \n",
    "        Alternatively, first PCA/ICA transform the sequences. (Perhaps a better idea? \n",
    "        Otherwise, the estimation of relative noise levels for each sequence would be manual/\n",
    "        judgmental process)\n",
    "        Still nice to have a manual over-ride. \n",
    "        \"\"\"\n",
    "        num_obs_t = y_vector_arr.shape[2]\n",
    "        if num_obs_t < 1:\n",
    "            print(\"Error: Empty observation vector in viterbi algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Dynamic programming \n",
    "            # Maximal prior sequence given current evidence, conditioned on current state\n",
    "            # Note: to extent to multiple sequences of different types, need to learn different B matrices!\n",
    "            alpha_prev = np.multiply(self.pi, \n",
    "                                     np.prod([self.B[s, :, y_vector_arr[s, :, 0]] \n",
    "                                              for s in range(self.num_sensors)], axis=0))  # (num_states x num_seq)\n",
    "#                                      self.B[:, y_vector_arr[:, 0]])  # (num_states x num_seq)\n",
    "            alpha_prev = np.log(np.prod(alpha_prev, axis=1).reshape(self.num_states, 1))  # aggregate across sequences\n",
    "            result = alpha_prev.copy().T  # one entry for each time t\n",
    "            for h in range(1, num_obs_t):\n",
    "                alpha_prev_new = np.prod([self.B[s, :, y_vector_arr[s, :, h]] \n",
    "                                          for s in range(self.num_sensors)], axis=(0, 1)).reshape(1, self.num_states)\n",
    "#                 alpha_prev_new = np.prod(self.B[:, y_vector_arr[:, h]], axis=1).reshape(1, self.B.shape[0])\n",
    "                alpha_prev = np.add(np.max(np.add(np.log(self.A), alpha_prev), axis=0),  # (1 x num_states)\n",
    "                                    np.log(alpha_prev_new)).T\n",
    "                result = np.vstack((result, alpha_prev.T))\n",
    "        # Backtrack and return the most likely sequence\n",
    "        most_likely_seq = np.argmax(result, axis=1).tolist()\n",
    "        return most_likely_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(y_vector, t_past):\n",
    "        \"\"\"\n",
    "        Calculates beta_i(t) for all states i.\n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        t_past integer representing past time ending the backward algorithm\n",
    "        Returns numpy array (T, num states); each row represents beta_i(t) for 1< t<T.\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"bwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in backward algorithm\")\n",
    "            return None\n",
    "        if t_past < 0 or t_past > t:\n",
    "            print(\"Error: invalid t_past in backward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            beta_next = np.ones((num_states, 1))\n",
    "            result = beta_next.copy().T\n",
    "            for h in range(t - 2, t_past - 1, -1):\n",
    "#                 print(beta_next, h)\n",
    "                beta_next = np.dot(A, \n",
    "                                   np.multiply(np.prod([B[s, :, y_vector[s, h + 1]] \n",
    "                                                        for s in range(num_sensors)], \n",
    "                                                       axis=0).reshape(num_states, 1), \n",
    "                                               beta_next)\n",
    "                                  )\n",
    "                beta_next = np.divide(beta_next, np.sum(beta_next))\n",
    "                result = np.vstack((result, beta_next.T))\n",
    "            result = np.array(result[::-1])\n",
    "            return result\n",
    "        \n",
    "def forward(y_vector):\n",
    "        \"\"\"\n",
    "        Calculates alpha_i(t) for all states i, and all t. Filtering. \n",
    "        y_vector numpy array (num sensors, num emissions)\n",
    "        Returns numpy array (T, num states); each row represents alpha_i(t) for 1< t<T\n",
    "        \n",
    "        To be computed separately for each sequence of observations Y_r.\n",
    "        \"\"\"\n",
    "#         print(\"fwd\")\n",
    "        t = y_vector.shape[1]\n",
    "        if t < 1:\n",
    "            print(\"Error: Empty observation vector in forward algorithm\")\n",
    "            return None\n",
    "        else:\n",
    "            # Avoid recursion here because python has a hard recursion depth limitation; \n",
    "            # also, dynamic programming is more efficient. \n",
    "            # Probability observe y_h given were in state k previously, over all states k\n",
    "            alpha_prev = np.multiply(pi, np.prod([B[s, :, y_vector[s, 0]] for s in range(num_sensors)], \n",
    "                                                      axis=0).reshape(num_states, 1))\n",
    "            result = alpha_prev.copy().T  # one entry for each time t\n",
    "            for h in range(1, t):\n",
    "                print(alpha_prev, h)\n",
    "                alpha_prev = np.multiply(np.dot(A.T, alpha_prev), \n",
    "                                         np.prod([B[s, :, y_vector[s, h]] for s in range(num_sensors)], \n",
    "                                                 axis=0).reshape(num_states, 1))\n",
    "                alpha_prev = np.divide(alpha_prev, np.sum(alpha_prev))  # scaled version\n",
    "                result = np.vstack((result, alpha_prev.T))\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENTATION AND VALIDATION OF HMM CLASS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TOY EXAMPLE, WIKIPEDIA CHICKEN/EGG\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Case - wikipedia\n",
    "# https://en.wikipedia.org/wiki/Baum–Welch_algorithm\n",
    "A = np.array([[0.5, 0.5], [0.3, 0.7]])\n",
    "B = np.array([[[0.3, 0.7], [0.8, 0.2]]])  # (num_sensors x num_states x num_emissions)\n",
    "pi = np.array([[0.2], [0.8]])\n",
    "\n",
    "# obs = np.array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]*100000])\n",
    "obs = np.array([[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]]])  # (num_sensors x num_sequences x num_obs (T))\n",
    "obs = np.array([[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]],  # Two sensors, one sequences\n",
    "               [[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]]])\n",
    "obs = np.array([[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]], # Two sensors, two sequences\n",
    "               [[0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 iterations.\n",
      "CPU times: user 72.5 ms, sys: 3.67 ms, total: 76.2 ms\n",
      "Wall time: 82.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "After one iteration, updated HMM parameters should be:\n",
    "\n",
    "A = np.array([[0.3973, 0.6027], \n",
    "              [0.1833, 0.8167]])\n",
    "B = np.array([[0.0908, 0.9092], \n",
    "              [0.5752, 0.4248]])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "wiki_bw = hmm_multi_discrete(A, B, pi)\n",
    "\n",
    "# N=0, E=1\n",
    "wiki_bw.fit(obs, max_iter=30)\n",
    "\n",
    "# Time complexity seems linear in T, as it should be (maybe factor of 6 for shorter, 3 for longer?)\n",
    "# 10-length sequence: ~24 ms?\n",
    "# 200-length sequence: <3 sec\n",
    "# 10,000-length sequence: 7 min, 33s (453 sec)\n",
    "# 100,000 length sequence: >5 hours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51577386, 0.48422614],\n",
       "       [0.15197986, 0.84802014]])"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "array([[0.43921478, 0.56078522],\n",
    "       [0.21445682, 0.78554318]])\n",
    "       \n",
    "array([[0.51577386, 0.48422614],\n",
    "       [0.15197986, 0.84802014]])\n",
    "\"\"\"\n",
    "wiki_bw.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.62501454e-02, 9.33749855e-01],\n",
       "        [9.99999961e-01, 3.91817883e-08]]])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "array([[0.46160107, 0.53839893],\n",
    "       [0.91501557, 0.08498443]])\n",
    "       \n",
    "array([[6.62501454e-02, 9.33749855e-01],\n",
    "       [9.99999961e-01, 3.91817883e-08]])\n",
    "\"\"\"\n",
    "wiki_bw.B\n",
    "# Need to switch rows of B... Why??? And switch columns\n",
    "# I think the code is right, though it doesn't agree with wikipedia. And my converged probabilities look right. \n",
    "# state 1 is egg-producing, state 2 is non-egg-producing\n",
    "# obs 1 is no egg, obs2 is egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.87134381e-19],\n",
       "       [1.00000000e+00]])"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "array([[0.07187023],\n",
    "       [0.92812977]])\n",
    "       \n",
    "array([[1.87134381e-19],\n",
    "       [1.00000000e+00]])\n",
    "\"\"\"\n",
    "wiki_bw.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obs = [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
    "# State 2 (\"1's\") is non-egg producing, state 1 (\"0's\") is egg-producing\n",
    "wiki_bw.viterbi(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO (DONE?): MAKE THE FOLLOWING FUNCTIONS PART OF THE BAUM-WELCH CLASS AND RENAME CLASS TO HMM.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probability of an observed sequence\n",
    "\n",
    "Using the forward algorithm (dynamic programming).\n",
    "This is the same as the algorithm coded above; \n",
    "Sum over all i and select the last t. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probability of the latent variables:\n",
    "Filtering; Distribution over states of the last latent variable, given the observed sequence.\n",
    "\n",
    "Using the forward algorithm (dynamic programming).\n",
    "This is the same as the algorithm coded above; \n",
    "Select the last t, then normalize the resulting pseudo-probabilities. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probability of the latent variables:\n",
    "Smoothing; Distribution over states of some middle latent variable, at some point k steps in the past from time t.\n",
    "\n",
    "Using the forward-backward algorithm.\n",
    "\n",
    "Implemented above in HMM class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probability of the latent variables:\n",
    "Most Likely Explanation; Joint probability of the entire sequence of hidden states \n",
    "that generated an entire sequence of observations.  (ie, part of speech tagging)\n",
    "\n",
    "Using Viterbi algorithm.\n",
    "\n",
    "Implemented above in HMM class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MOX GAS SENSOR REAL-WORLD DATA EXPERIMENTATION/ACTIVITY RECOGNITION\n",
    "\n",
    "Now apply class written above to the data_hmm, MOX gas sensor data prepared at the beginning of the notebook.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586570, 24)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hmm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>...</th>\n",
       "      <th>R1_binned</th>\n",
       "      <th>R2_binned</th>\n",
       "      <th>R3_binned</th>\n",
       "      <th>R4_binned</th>\n",
       "      <th>R5_binned</th>\n",
       "      <th>R6_binned</th>\n",
       "      <th>R7_binned</th>\n",
       "      <th>R8_binned</th>\n",
       "      <th>Temp._binned</th>\n",
       "      <th>Humidity_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>12.8102</td>\n",
       "      <td>10.3665</td>\n",
       "      <td>10.4529</td>\n",
       "      <td>11.6742</td>\n",
       "      <td>13.4941</td>\n",
       "      <td>13.2749</td>\n",
       "      <td>8.30531</td>\n",
       "      <td>9.04553</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>12.8097</td>\n",
       "      <td>10.3655</td>\n",
       "      <td>10.4523</td>\n",
       "      <td>11.6734</td>\n",
       "      <td>13.4934</td>\n",
       "      <td>13.2740</td>\n",
       "      <td>8.30527</td>\n",
       "      <td>9.04545</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>12.8088</td>\n",
       "      <td>10.3645</td>\n",
       "      <td>10.4516</td>\n",
       "      <td>11.6731</td>\n",
       "      <td>13.4930</td>\n",
       "      <td>13.2730</td>\n",
       "      <td>8.30523</td>\n",
       "      <td>9.04538</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>12.8080</td>\n",
       "      <td>10.3638</td>\n",
       "      <td>10.4508</td>\n",
       "      <td>11.6727</td>\n",
       "      <td>13.4922</td>\n",
       "      <td>13.2719</td>\n",
       "      <td>8.30520</td>\n",
       "      <td>9.04516</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>12.8078</td>\n",
       "      <td>10.3628</td>\n",
       "      <td>10.4503</td>\n",
       "      <td>11.6722</td>\n",
       "      <td>13.4914</td>\n",
       "      <td>13.2708</td>\n",
       "      <td>8.30517</td>\n",
       "      <td>9.04511</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time       R1       R2       R3       R4       R5       R6  \\\n",
       "0   0  0.000021  12.8102  10.3665  10.4529  11.6742  13.4941  13.2749   \n",
       "1   0  0.000309  12.8097  10.3655  10.4523  11.6734  13.4934  13.2740   \n",
       "2   0  0.000587  12.8088  10.3645  10.4516  11.6731  13.4930  13.2730   \n",
       "3   0  0.000865  12.8080  10.3638  10.4508  11.6727  13.4922  13.2719   \n",
       "4   0  0.001144  12.8078  10.3628  10.4503  11.6722  13.4914  13.2708   \n",
       "\n",
       "        R7       R8  ...  R1_binned  R2_binned R3_binned R4_binned  R5_binned  \\\n",
       "0  8.30531  9.04553  ...          8          9         9         9          1   \n",
       "1  8.30527  9.04545  ...          8          9         9         9          1   \n",
       "2  8.30523  9.04538  ...          8          9         9         9          1   \n",
       "3  8.30520  9.04516  ...          8          9         9         9          1   \n",
       "4  8.30517  9.04511  ...          8          9         9         9          1   \n",
       "\n",
       "   R6_binned  R7_binned  R8_binned  Temp._binned  Humidity_binned  \n",
       "0          2          9          9             3                5  \n",
       "1          2          9          9             3                5  \n",
       "2          2          9          9             3                5  \n",
       "3          2          9          9             3                5  \n",
       "4          2          9          9             3                5  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hmm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Emission space too large...\n",
    "\n",
    "# Center and scale, then PCA/ICA on the obs sequences first to reduce them before binning?\n",
    "# Then, use sensor fusion to linearly combine the disparate sequences into a single observation sequence\n",
    "\n",
    "# To reduce length of sequences, could sample them at a certain frequency. \n",
    "\n",
    "# Hmm inference time complexity is O(T * |state space|^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Typically want to initialize B to some good guess (Rabiner)\n",
    "\n",
    "# See 'Vector Quantization in Speech Encoding' Makhoul (1985) for codebook discretization\n",
    "# Or can use continuous observation densities, say mixture of Gaussians (GMM) with a diagonal covariance matrix\n",
    "# The latter will also help cut down on the number of parameters in my HMM...maybe\n",
    "\n",
    "# Log-transform data to normalize it\n",
    "# Fit a GMM for each separate observation dimension (ie multiple B matrices)\n",
    "\n",
    "# Set minimum values in matrices A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data prep\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Center and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deprecated: Sensor fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log-transform and check normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optionally, bin/discretize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POC 0: Use binned raw data as discrete observation vector; sample data. \n",
    "\n",
    "POC 1: PCA/ICA centered and scaled obs sequences; log-transform; sample data\n",
    "Apply as continuous observation vector.\n",
    "\n",
    "POC 2: Same as POC 1 but bin/discretize (log-transformed) data, apply as discrete observation vector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POC 0 HMM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(MY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 sequences dropped due to inconsistent sampling\n",
      "500000 points sampled with target window size of 190; 27 discrete ranges per sequence\n",
      "Observation sequence sampling frequency of 85.24%\n"
     ]
    }
   ],
   "source": [
    "num_states_mox = 3  # background, wine, banana\n",
    "num_emissions_mox = bin_ct_discretize  # binned into 10 deciles\n",
    "num_sensors_mox = 10  # vars_binned\n",
    "num_sequences = len(data_hmm.id.unique())  # 99\n",
    "\n",
    "A_mox = np.full((num_states_mox, num_states_mox), 1./num_states_mox)\n",
    "\n",
    "# HMM doesn't learn much with random uniform initialization\n",
    "# B_mox = np.array([np.full((num_states_mox, num_emissions_mox), 1./num_emissions_mox)] * num_sensors_mox)\n",
    "# With random initialization it learns!!\n",
    "B_mox_temp = np.random.randint(1,10,(num_states_mox, num_emissions_mox))\n",
    "B_mox = np.array([np.divide(B_mox_temp.T, np.sum(B_mox_temp, axis=1)).T] * num_sensors_mox)\n",
    "\n",
    "pi_mox = np.full((num_states_mox, 1), 1./num_states_mox)\n",
    "\n",
    "total_sampled_pts = 500000.0\n",
    "target_window_size = 190  # Viterbi results are sensitive to this parameter\n",
    "# I probably need to trade off width of window with # data points sampled\n",
    "\n",
    "\"\"\"\n",
    "Is it really appropriate to treat the different sensed experiments as independent observation sequences?\n",
    "\"\"\"\n",
    "# Subtract 1 to avoid running over end of sequence\n",
    "num_ranges_per_seq = math.ceil(total_sampled_pts / target_window_size / num_sequences)\n",
    "\n",
    "# Sample within sequences\n",
    "data_hmm_seq = [data_hmm.loc[data_hmm.id == i, vars_binned + [\"class\"]].reset_index() for i in data_hmm.id.unique()]\n",
    "sample_by_seq = [math.ceil(data_hmm_seq[i].shape[0] / num_ranges_per_seq) for i in range(num_sequences)]\n",
    "# Don't want sampled windows to overlap\n",
    "window_size_seq = [min(target_window_size, sample_by_seq[i]) for i in range(num_sequences)]\n",
    "\n",
    "sampled_indexes_seq = [range(0, data_hmm_seq[i].shape[0], sample_by_seq[i]) for i in range(num_sequences)]\n",
    "sampled_indexes_seq = [np.array([j for i in sampled_indexes_seq[k] for j in range(i, i + window_size_seq[k])]) \n",
    "                       for k in range(num_sequences)]\n",
    "# Counter([len(sampled_indexes_seq[i]) for i in range(num_sequences)])\n",
    "sampled_indexes_seq_len = \\\n",
    "Counter([len(sampled_indexes_seq[i]) for i in range(num_sequences)]).most_common(1)[0][0]\n",
    "print(\"%d sequences dropped due to inconsistent sampling\"\n",
    "      %(len(Counter([len(sampled_indexes_seq[i]) for i in range(num_sequences)])) - 1))\n",
    "# # Remove sequences that don't have mode # of sampled points (just a couple)\n",
    "# data_hmm_seq = \\\n",
    "# data_hmm_seq[np.array([len(sampled_indexes_seq[i]) == sampled_indexes_seq_len for i in range(num_sequences)])]\n",
    "\n",
    "# # Update for dropped sequences\n",
    "# num_sequences = len(data_hmm_seq)\n",
    "\n",
    "print(\"%d points sampled with target window size of %d; %d discrete ranges per sequence\"\n",
    "      %(total_sampled_pts, target_window_size, num_ranges_per_seq))\n",
    "\n",
    "# Treat each id as a separate sequence!!! Sample within sequences \n",
    "# obs_mox = np.stack([data_hmm_seq[i].loc[sampled_indexes_seq[i], vars_binned].values for i in range(num_sequences)\n",
    "#                    if len(sampled_indexes_seq[i]) == sampled_indexes_seq_len])\n",
    "obs_min_len = 4000\n",
    "obs_mox = np.stack([data_hmm_seq[i].loc[:obs_min_len, vars_binned].values for i in range(num_sequences)\n",
    "                   if data_hmm_seq[i].shape[0] >= obs_min_len])   # Remove really short sequences\n",
    "obs_mox = np.moveaxis(obs_mox, 2, 0)\n",
    "# obs_mox = np.expand_dims(obs_mox, 1)  # (num_sensors, num_sequences, num_obs (T))\n",
    "# sampled_true_states = np.stack([data_hmm_seq[i].loc[sampled_indexes_seq[i], [\"class\"]].values \n",
    "#                                 for i in range(num_sequences) \n",
    "#                                 if len(sampled_indexes_seq[i]) == sampled_indexes_seq_len])\n",
    "sampled_true_states = np.stack([data_hmm_seq[i].loc[:obs_min_len, [\"class\"]].values \n",
    "                                for i in range(num_sequences) \n",
    "                                if data_hmm_seq[i].shape[0] >= obs_min_len])\n",
    "sampled_true_states = np.squeeze(np.moveaxis(sampled_true_states, 2, 0))\n",
    "\n",
    "print(\"Observation sequence sampling frequency of %3.2f%%\"%(100 * total_sampled_pts / data_hmm.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 95, 4001)"
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_mox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 4001)"
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_true_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([684359,      0, 541173,      0,      0, 915135,      0, 865216,\n",
       "             0, 795067]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]))"
      ]
     },
     "execution_count": 1154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(obs_mox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 iterations.\n",
      "CPU times: user 12min 11s, sys: 4.35 s, total: 12min 15s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hmm_mox = hmm_multi_discrete(A_mox, B_mox, pi_mox)\n",
    "\n",
    "# N=0, E=1\n",
    "hmm_mox.fit(obs_mox, max_iter=30)\n",
    "# 100K, 50 takes less iterations, same time as 50K-20, <2 min\n",
    "# 400K, 500 takes <7 min for 5 iters\n",
    "# 500K, 1500 takes 4 iters, 3 min, best viterbi results with more data\n",
    "# 500K, 5000 takes 9 iterations, 40 sec\n",
    "# Just take all data? Up to first 4000 pts (no sampling) takes 10 iterations, 12 min\n",
    "\n",
    "# Too few iterations overall a sign learning isn't occurring?? actually too many sequences dropped above... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99055184e-01, 9.44815908e-04, 1.87597371e-15],\n",
       "       [9.43771483e-04, 9.98582526e-01, 4.73702071e-04],\n",
       "       [1.00820934e-05, 4.13068077e-04, 9.99576850e-01]])"
      ]
     },
     "execution_count": 1156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "array([[0.98539741, 0.003499  , 0.01110359],\n",
    "       [0.01953505, 0.97315361, 0.00731134],\n",
    "       [0.00949344, 0.00310452, 0.98740204]])\n",
    "\"\"\"\n",
    "hmm_mox.A  # This is correct, actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.04179455e-001, 1.53857510e-001, 3.00588501e-001,\n",
       "         3.05283680e-001, 3.60908546e-002],\n",
       "        [4.95803632e-064, 3.90337462e-063, 6.94335286e-015,\n",
       "         8.00271228e-001, 1.99728772e-001],\n",
       "        [8.81627157e-165, 2.02127678e-175, 8.68998316e-090,\n",
       "         2.06123665e-001, 7.93876335e-001]],\n",
       "\n",
       "       [[2.38725531e-001, 2.43475509e-001, 3.52908081e-001,\n",
       "         1.35965833e-001, 2.89250460e-002],\n",
       "        [3.15699135e-016, 1.77278100e-002, 2.91904055e-002,\n",
       "         8.57281051e-001, 9.58007337e-002],\n",
       "        [1.71313919e-307, 7.29075914e-106, 7.59825554e-063,\n",
       "         3.77991214e-010, 1.00000000e+000]]])"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_mox.B[:2]  # This can't be verified, but it looks like learning is occurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09576075, 0.20130406, 0.34044187, 0.25236966, 0.11012366],\n",
       "        [0.05002647, 0.11280368, 0.29961266, 0.28999965, 0.24755754],\n",
       "        [0.0484409 , 0.14113284, 0.36284783, 0.38191467, 0.06566376]],\n",
       "\n",
       "       [[0.19214693, 0.35163369, 0.25485963, 0.13181891, 0.06954084],\n",
       "        [0.15446859, 0.25443011, 0.28102889, 0.20009486, 0.10997756],\n",
       "        [0.28587163, 0.30460422, 0.26088416, 0.05937   , 0.08926999]]])"
      ]
     },
     "execution_count": 1158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_mox.B[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14737445],\n",
       "       [0.29615658],\n",
       "       [0.55646897]])"
      ]
     },
     "execution_count": 1159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_mox.pi  # Nice! Sensible result after break apart sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/LaCie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:283: RuntimeWarning: divide by zero encountered in log\n",
      "/Volumes/LaCie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:276: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 s, sys: 167 ms, total: 26.5 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Important: Viterbi independent sequences separately.\n",
    "\"\"\"\n",
    "inferred_states_mox = np.array([hmm_mox.viterbi(np.expand_dims(obs_mox[:,i,:], 1)) for i in range(obs_mox.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 4001)"
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_states_mox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inferred_states_mox_mc = [Counter(i).most_common(1)[0][0] for i in inferred_states_mox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_true_states_mc = [Counter(i).most_common(1)[0][0] for i in sampled_true_states]  # uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viterbi_results_hmm_mox = \\\n",
    "pd.merge(pd.DataFrame(inferred_states_mox_mc, columns=[\"inferred_state\"]), \n",
    "         pd.DataFrame(sampled_true_states_mc, columns=[\"true_state\"]),\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "viterbi_results_hmm_mox = \\\n",
    "pd.merge(viterbi_results_hmm_mox, \n",
    "        pd.DataFrame(np.ones((viterbi_results_hmm_mox.shape[0], 1)), columns=[\"counts\"]),\n",
    "        left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_state</th>\n",
       "      <th>inferred_state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">background</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">banana</th>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wine</th>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           counts\n",
       "true_state inferred_state        \n",
       "background 0                    1\n",
       "           1                   10\n",
       "           2                   18\n",
       "banana     0                    8\n",
       "           1                    8\n",
       "           2                   16\n",
       "wine       0                   25\n",
       "           1                    5\n",
       "           2                    4"
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "With more data, I seem to at least arrive at unimodal predictions of inferred state\n",
    "\"\"\"\n",
    "viterbi_results_hmm_mox.groupby(['true_state', 'inferred_state']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POC 1 HMM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POC 2 HMM\n",
    "\n",
    "...Save for later? Parameter space may explode... \n",
    "I could try a semi-continuous GMHMM as described in Gutierrez-Osuna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Check we get the same result for POC 0 with the hmmlearn package\n",
    " \n",
    " Results as expected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "# How to handle sensor fusion here??\n",
    "# Not sure I'm handling this correctly\n",
    "# https://github.com/hmmlearn/hmmlearn/issues/128\n",
    "\n",
    "# X_mox = obs_mox[0,:,:].flatten()\n",
    "X_mox = obs_mox.flatten()\n",
    "X_mox = X_mox.reshape(X_mox.shape[0], 1)\n",
    "lengths_mox = [obs_mox.shape[2]] * (obs_mox.shape[1] * obs_mox.shape[0])  # (10, 95, 4001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 2.23 s, total: 4min 27s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3x faster than my code\n",
    "\n",
    "# model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "# model = hmm.GMMHMM(n_components=3, covariance_type=\"full\")\n",
    "model = hmm.MultinomialHMM(n_components=3\n",
    "#                            , n_features=num_emissions_mox\n",
    "                          )\n",
    "\n",
    "model.fit(X_mox, lengths_mox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check hmm fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_features  # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34308729, 0.29269944, 0.36421327])"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.startprob_  # reasonably intelligent, similar to mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98652592e-01, 3.00350345e-04, 1.04705763e-03],\n",
       "       [6.33247424e-04, 9.99366753e-01, 5.32124869e-38],\n",
       "       [1.13262956e-03, 2.92946527e-39, 9.98867370e-01]])"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transmat_   # correct, same as as mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.41642198e-01, 5.91978136e-07, 4.07627128e-06, 5.58349265e-01,\n",
       "        3.86868154e-06],\n",
       "       [9.76141537e-33, 1.05028880e-34, 5.37377695e-33, 1.35527809e-05,\n",
       "        9.99986447e-01],\n",
       "       [1.26598923e-06, 3.71606414e-01, 6.28391042e-01, 1.27763654e-06,\n",
       "        2.98557204e-36]])"
      ]
     },
     "execution_count": 1219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emissionprob_  # Just one B matrix... sad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Go on to validating predicted results via Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_true_states_mc_hmmlearn = sampled_true_states.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 397 ms, total: 2.79 s\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inferred_states_mox_mc_hmmlearn = model.predict(X_mox)\n",
    "inferred_states_mox_mc_hmmlearn = model.decode(X_mox, algorithm=\"viterbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inferred_states_mox_mc_hmmlearn = inferred_states_mox_mc_hmmlearn[1]  # for decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800950,)"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_states_mox_mc_hmmlearn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viterbi_results_hmm_mox_hmmlearn = \\\n",
    "pd.merge(pd.DataFrame(inferred_states_mox_mc_hmmlearn, columns=[\"inferred_state\"]), \n",
    "         pd.DataFrame(sampled_true_states_mc_hmmlearn, columns=[\"true_state\"]),\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "viterbi_results_hmm_mox_hmmlearn = \\\n",
    "pd.merge(viterbi_results_hmm_mox_hmmlearn, \n",
    "        pd.DataFrame(np.ones((viterbi_results_hmm_mox_hmmlearn.shape[0], 1)), columns=[\"counts\"]),\n",
    "        left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_state</th>\n",
       "      <th>inferred_state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">background</th>\n",
       "      <th>0</th>\n",
       "      <td>64989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">banana</th>\n",
       "      <th>0</th>\n",
       "      <td>43555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wine</th>\n",
       "      <th>0</th>\n",
       "      <td>74495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           counts\n",
       "true_state inferred_state        \n",
       "background 0                64989\n",
       "           1                50954\n",
       "           2                   86\n",
       "banana     0                43555\n",
       "           1                69934\n",
       "           2                14543\n",
       "wine       0                74495\n",
       "           1                23054\n",
       "           2                38485"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like results for my code, results in terms of prediction aren't impressive\n",
    "# My results are actually a bit more impressive (clearer clustering to mutually exclusive states),\n",
    "# probably due to my handling of sensor fusion (independent sequences) versus complementary sequences. \n",
    "\"\"\"\n",
    "# predict with decode\n",
    "\n",
    "counts\n",
    "true_state\tinferred_state\t\n",
    "background\t0\t64989\n",
    "1\t50954\n",
    "2\t86\n",
    "banana\t0\t43555\n",
    "1\t69934\n",
    "2\t14543\n",
    "wine\t0\t74495\n",
    "1\t23054\n",
    "2\t38485\n",
    "# decode with viterbi\n",
    "\n",
    "same\n",
    "\"\"\"\n",
    "viterbi_results_hmm_mox_hmmlearn.groupby(['true_state', 'inferred_state']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
